{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MNIST\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, TensorDataset\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"all_data.csv\")\n",
    "\n",
    "# target 열에 데이터가 있으면 train, 없으면 final 나누기\n",
    "train = df[df.target.notnull()]\n",
    "final = df[df.target.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test and split 임포트\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#데이터셋 분리\n",
    "train, test = train_test_split(train, test_size=0.2)\n",
    "\n",
    "# Prepare data for DataLoader\n",
    "X_train = torch.tensor(train.drop('target', axis=1).values, dtype=torch.float32)\n",
    "y_train = torch.tensor(train['target'].values, dtype=torch.long)\n",
    "X_test = torch.tensor(test.drop('target', axis=1).values, dtype=torch.float32)\n",
    "y_test = torch.tensor(test['target'].values, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터로더 만들기\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28x28x1 => 10\n",
    "#sequential 순차적으로 블럭을 쌓아서 만든다. 플래튼부터 소프트맥스까지 하나씩 거쳐가는 형식이다.\n",
    "#보통은 시퀀셜이 아닌 클래스로 모델을 만든다.\n",
    "mnist_fc_model = nn.Sequential(\n",
    "    nn.Flatten(), #28x28x1을 784로 펼치는 역할 내가 넣으려는 데이터는 2차원이 아니므로 필요 없을듯\n",
    "    nn.Linear(in_features=48, out_features=256), #in_features, out_features를 맞추주는 것이 중요\n",
    "    nn.ReLU(), #요즘은 렐루, 리켈루를 많이 쓴다. 무난하게는 ReLU함수 사용\n",
    "    nn.Linear(in_features=256, out_features=2), #나의 경우는 아웃피처가 2가 되어야함(정상 불량)\n",
    "    nn.Softmax() #꼭 해줘야함. 확률값으로 바꿔주는 것\n",
    ")\n",
    "#다항함수 하나가 Linear고 2개를 쌓은 모습이다.\n",
    "\n",
    "# Model definition\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=X_train.shape[1], out_features=256), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=256, out_features=2)  # Assuming binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만든 모델을 device(cuda)로 전달하자\n",
    "#device는 위에 cuda, cpu 부분 참고\n",
    "#연산을 GPU의 VRAM으로 모델을 보내줌 데이터는 아직 안보냄 후에 배치로 데이터를 보낼 것이다.\n",
    "mnist_fc_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실제 학습이 일어나는 train() 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'inf' from 'torch' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optim\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "File \u001b[1;32mc:\\lg_capstone\\lg_capstone\\Lib\\site-packages\\torch\\optim\\__init__.py:9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m:mod:`torch.optim` is a package implementing various optimization algorithms.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mfuture.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lr_scheduler, swa_utils\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madadelta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adadelta\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madagrad\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adagrad\n",
      "File \u001b[1;32mc:\\lg_capstone\\lg_capstone\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:24\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     Any,\n\u001b[0;32m     10\u001b[0m     Callable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     Union,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mweakref\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ref\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inf, Tensor\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer\n\u001b[0;32m     28\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLambdaLR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiplicativeLR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLRScheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     45\u001b[0m ]\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'inf' from 'torch' (unknown location)"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    epochs = 10\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        print(f'epochs:{epoch + 1} / {epochs}')\n",
    "        \n",
    "        for x_t, y_t in train_loader:\n",
    "            x_t = x_t.to(device)\n",
    "            y_t = y_t.to(device)\n",
    "            \n",
    "            pred = model(x_t)\n",
    "            loss = criterion(pred, y_t)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        # Evaluate model on test_loader\n",
    "        for xx, yy in test_loader:  \n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            pred = model(xx)\n",
    "            _, predicted = torch.max(pred, 1)\n",
    "            correct += predicted.eq(yy.data).sum()\n",
    "\n",
    "        print(f'test_accuracy: {(100. * correct / len(test_loader.dataset)).item()}')\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Total training time: {elapsed_time // 60} minutes {elapsed_time % 60} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(mnist_fc_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg_capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
